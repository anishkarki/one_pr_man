{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d758b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to http::localhost:19200...\n",
      "‚úÖ Connected to OpenSearch\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import http.client\n",
    "from datetime import datetime\n",
    "\n",
    "# Increase header limit\n",
    "http.client._MAXHEADERS = 1000\n",
    "\n",
    "# Configuration\n",
    "HOST = 'localhost'\n",
    "PORT = 19200\n",
    "PROTOCOL = 'http'\n",
    "AUTH = ('admin', 'OpenSearch@2024')\n",
    "VERIFY_SSL = False\n",
    "MODEL_ID = \"RLmMzpoBDLC7DRstN6vK\"\n",
    "TARGET_HOST = \"patroni1\"  # üéØ The specific host we want to index\n",
    "\n",
    "BASE_URL = f\"{PROTOCOL}::{HOST}:{PORT}\"\n",
    "\n",
    "def run_request(method, endpoint, body=None):\n",
    "    url = f\"{PROTOCOL}://{HOST}:{PORT}/{endpoint}\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        if method == \"GET\":\n",
    "            resp = requests.get(url, auth=AUTH, verify=VERIFY_SSL, json=body, headers=headers)\n",
    "        elif method == \"POST\":\n",
    "            resp = requests.post(url, auth=AUTH, verify=VERIFY_SSL, json=body, headers=headers)\n",
    "        elif method == \"PUT\":\n",
    "            resp = requests.put(url, auth=AUTH, verify=VERIFY_SSL, json=body, headers=headers)\n",
    "        elif method == \"DELETE\":\n",
    "            resp = requests.delete(url, auth=AUTH, verify=VERIFY_SSL, json=body, headers=headers)\n",
    "        elif method == \"HEAD\":\n",
    "            resp = requests.head(url, auth=AUTH, verify=VERIFY_SSL, json=body, headers=headers)\n",
    "        else:\n",
    "            print(f\"Unsupported method: {method}\")\n",
    "            return None\n",
    "        return resp\n",
    "    except Exception as e:\n",
    "        print(f\"Connection Error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(f\"Connecting to {BASE_URL}...\")\n",
    "resp = run_request(\"GET\", \"\")\n",
    "if resp and resp.status_code == 200:\n",
    "    print(\"‚úÖ Connected to OpenSearch\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to connect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6d45b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Model ID: RLmMzpoBDLC7DRstN6vK\n",
      "Model State: DEPLOYED\n"
     ]
    }
   ],
   "source": [
    "# 1. Verify Model Availability\n",
    "print(f\"Checking Model ID: {MODEL_ID}\")\n",
    "resp = run_request(\"GET\", f\"_plugins/_ml/models/{MODEL_ID}\")\n",
    "if resp and resp.status_code == 200:\n",
    "    state = resp.json().get(\"model_state\")\n",
    "    print(f\"Model State: {state}\")\n",
    "    if state != \"DEPLOYED\":\n",
    "        print(\"‚ö†Ô∏è Model is not deployed. Please deploy it using the previous notebook.\")\n",
    "else:\n",
    "    print(\"‚ùå Model not found. Please check the ID.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9f1bcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Pipeline 'future-host-pipeline' for host 'patroni1'...\n",
      "{\"acknowledged\":true}\n"
     ]
    }
   ],
   "source": [
    "# 2. Create Filtering Pipeline\n",
    "# This pipeline does two things:\n",
    "# 1. DROPS any document where host.name is NOT 'patroni1'.\n",
    "# 2. Generates embeddings for the remaining documents.\n",
    "\n",
    "pipeline_id = \"future-host-pipeline\"\n",
    "\n",
    "pipeline_body = {\n",
    "  \"description\": f\"Filter logs for {TARGET_HOST} and vectorize\",\n",
    "  \"processors\": [\n",
    "    {\n",
    "      \"drop\": {\n",
    "        \"if\": f\"ctx.host?.name != '{TARGET_HOST}'\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"text_embedding\": {\n",
    "        \"model_id\": MODEL_ID,\n",
    "        \"field_map\": {\n",
    "          \"_raw\": \"message_embedding\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "print(f\"Creating Pipeline '{pipeline_id}' for host '{TARGET_HOST}'...\")\n",
    "resp = run_request(\"PUT\", f\"_ingest/pipeline/{pipeline_id}\", pipeline_body)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "912276e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Index 'patroni-future-host'...\n",
      "{\"acknowledged\":true,\"shards_acknowledged\":true,\"index\":\"patroni-future-host\"}\n",
      "{\"acknowledged\":true,\"shards_acknowledged\":true,\"index\":\"patroni-future-host\"}\n"
     ]
    }
   ],
   "source": [
    "# 3. Create Future Index\n",
    "# We create a new index that uses the pipeline by default.\n",
    "index_name = \"patroni-future-host\"\n",
    "\n",
    "run_request(\"DELETE\", index_name)\n",
    "\n",
    "index_body = {\n",
    "  \"settings\": {\n",
    "    \"index.knn\": True,\n",
    "    \"default_pipeline\": pipeline_id\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"timestamp\": { \"type\": \"date\" },\n",
    "      \"host\": { \n",
    "          \"properties\": {\n",
    "              \"name\": { \"type\": \"keyword\" }\n",
    "          }\n",
    "      },\n",
    "      \"_raw\": { \"type\": \"text\" },\n",
    "      \"message_embedding\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 384,\n",
    "        \"method\": {\n",
    "          \"name\": \"hnsw\",\n",
    "          \"engine\": \"lucene\",\n",
    "          \"parameters\": { \"m\": 16, \"ef_construction\": 128 }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "print(f\"Creating Index '{index_name}'...\")\n",
    "resp = run_request(\"PUT\", index_name, index_body)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fc6ffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating ingestion of 4 logs (2 from target, 2 from others)...\n",
      "Ingestion complete.\n",
      "Ingestion complete.\n"
     ]
    }
   ],
   "source": [
    "# 4. Simulate Future Log Ingestion\n",
    "# We will send a mix of logs from 'patroni1' (Target) and 'patroni2' (Ignored).\n",
    "# Only 'patroni1' logs should be indexed.\n",
    "\n",
    "logs = [\n",
    "    # TARGET HOST (patroni1) - Should be indexed\n",
    "    {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"host\": { \"name\": \"patroni1\" },\n",
    "        \"_raw\": \"2025-11-30 10:00:01 FATAL: database system is shutting down due to lack of disk space\"\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"host\": { \"name\": \"patroni1\" },\n",
    "        \"_raw\": \"2025-11-30 10:00:05 INFO: acquired leader lock\"\n",
    "    },\n",
    "    # IGNORED HOST (patroni2) - Should be dropped\n",
    "    {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"host\": { \"name\": \"patroni2\" },\n",
    "        \"_raw\": \"2025-11-30 10:00:02 INFO: following new leader\"\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"host\": { \"name\": \"patroni2\" },\n",
    "        \"_raw\": \"2025-11-30 10:00:03 WARNING: connection to master lost\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Simulating ingestion of 4 logs (2 from target, 2 from others)...\")\n",
    "\n",
    "for log in logs:\n",
    "    # We post directly to the index. The default_pipeline will intercept.\n",
    "    run_request(\"POST\", f\"{index_name}/_doc\", log)\n",
    "\n",
    "# Refresh to make data available\n",
    "run_request(\"POST\", f\"{index_name}/_refresh\")\n",
    "print(\"Ingestion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d42d4f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifying Index Content ---\n",
      "Total Documents Indexed: 2\n",
      "Indexed Log from: patroni1 | Message: 2025-11-30 10:00:01 FATAL: database system is shutting down due to lack of disk space\n",
      "Indexed Log from: patroni1 | Message: 2025-11-30 10:00:05 INFO: acquired leader lock\n",
      "\n",
      "‚úÖ SUCCESS: Only target host logs were indexed.\n"
     ]
    }
   ],
   "source": [
    "# 5. Verify Filtering\n",
    "# We expect exactly 2 documents in the index (only from patroni1).\n",
    "\n",
    "print(\"--- Verifying Index Content ---\")\n",
    "resp = run_request(\"GET\", f\"{index_name}/_search\")\n",
    "hits = resp.json().get(\"hits\", {}).get(\"hits\", [])\n",
    "\n",
    "print(f\"Total Documents Indexed: {len(hits)}\")\n",
    "for hit in hits:\n",
    "    src = hit[\"_source\"]\n",
    "    print(f\"Indexed Log from: {src.get('host', {}).get('name')} | Message: {src.get('_raw')}\")\n",
    "\n",
    "if len(hits) == 2:\n",
    "    print(\"\\n‚úÖ SUCCESS: Only target host logs were indexed.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå FAILURE: Expected 2 documents, found {len(hits)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7f77a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query: 'disk space issue'\n",
      "   [0.5224] [patroni1] 2025-11-30 10:00:01 FATAL: database system is shutting down due to lack of disk space\n",
      "   [0.3282] [patroni1] 2025-11-30 10:00:05 INFO: acquired leader lock\n",
      "\n",
      "üîç Query: 'leader election'\n",
      "   [0.4185] [patroni1] 2025-11-30 10:00:05 INFO: acquired leader lock\n",
      "   [0.3499] [patroni1] 2025-11-30 10:00:01 FATAL: database system is shutting down due to lack of disk space\n",
      "   [0.5224] [patroni1] 2025-11-30 10:00:01 FATAL: database system is shutting down due to lack of disk space\n",
      "   [0.3282] [patroni1] 2025-11-30 10:00:05 INFO: acquired leader lock\n",
      "\n",
      "üîç Query: 'leader election'\n",
      "   [0.4185] [patroni1] 2025-11-30 10:00:05 INFO: acquired leader lock\n",
      "   [0.3499] [patroni1] 2025-11-30 10:00:01 FATAL: database system is shutting down due to lack of disk space\n"
     ]
    }
   ],
   "source": [
    "# 6. Run Neural Search on Future Data\n",
    "# Now we search this new index.\n",
    "\n",
    "def neural_search(query_text):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"neural\": {\n",
    "                \"message_embedding\": {\n",
    "                    \"query_text\": query_text,\n",
    "                    \"model_id\": MODEL_ID,\n",
    "                    \"k\": 3\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"_raw\", \"host\"]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüîç Query: '{query_text}'\")\n",
    "    resp = run_request(\"GET\", f\"{index_name}/_search\", query)\n",
    "    hits = resp.json().get(\"hits\", {}).get(\"hits\", [])\n",
    "    \n",
    "    for hit in hits:\n",
    "        score = hit.get(\"_score\")\n",
    "        msg = hit.get(\"_source\").get(\"_raw\")\n",
    "        host = hit.get(\"_source\").get(\"host\", {}).get(\"name\")\n",
    "        print(f\"   [{score:.4f}] [{host}] {msg}\")\n",
    "\n",
    "neural_search(\"disk space issue\")\n",
    "neural_search(\"leader election\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
