{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2710b2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup Complete\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "OPENSEARCH_URL = \"http://localhost:19200\"\n",
    "AUTH = ('admin', 'OpenSearch@2024')\n",
    "VERIFY_SSL = False\n",
    "INDEX_NAME = \"patronidata\"\n",
    "\n",
    "def run_request(method, endpoint, body=None, params=None):\n",
    "    url = f\"{OPENSEARCH_URL}/{endpoint}\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        if method == \"GET\":\n",
    "            response = requests.get(url, auth=AUTH, verify=VERIFY_SSL, params=params, json=body, headers=headers)\n",
    "        elif method == \"POST\":\n",
    "            response = requests.post(url, auth=AUTH, verify=VERIFY_SSL, params=params, json=body, headers=headers)\n",
    "        elif method == \"PUT\":\n",
    "            response = requests.put(url, auth=AUTH, verify=VERIFY_SSL, params=params, json=body, headers=headers)\n",
    "        elif method == \"DELETE\":\n",
    "            response = requests.delete(url, auth=AUTH, verify=VERIFY_SSL, params=params, json=body, headers=headers)\n",
    "        elif method == \"HEAD\":\n",
    "            response = requests.head(url, auth=AUTH, verify=VERIFY_SSL, params=params, json=body, headers=headers)\n",
    "        else:\n",
    "            print(f\"Unsupported method: {method}\")\n",
    "            return None\n",
    "        \n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80299c99",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Prerequisite: Mock Data Setup\n",
    "Ensuring `patronidata` exists with relevant logs for our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab51ca35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index patronidata already exists.\n"
     ]
    }
   ],
   "source": [
    "# Check if index exists, if not create it with sample data\n",
    "check = run_request(\"HEAD\", INDEX_NAME)\n",
    "if check.status_code != 200:\n",
    "    print(f\"Creating mock {INDEX_NAME}...\")\n",
    "    run_request(\"PUT\", INDEX_NAME, {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"timestamp\": { \"type\": \"date\" },\n",
    "                \"hostname\": { \"type\": \"keyword\" },\n",
    "                \"component\": { \"type\": \"keyword\" },\n",
    "                \"message\": { \"type\": \"text\", \"analyzer\": \"standard\" },\n",
    "                \"level\": { \"type\": \"keyword\" }\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    # Sample Logs (Realistic Failover Scenario)\n",
    "    # Patroni: Python logging format\n",
    "    # Postgres: Standard prefix with PID\n",
    "    # Etcd: Go logging format\n",
    "    logs = [\n",
    "        # 1. Normal State\n",
    "        { \"timestamp\": \"2023-10-27T10:00:01\", \"hostname\": \"db-prod-01\", \"component\": \"patroni\", \"level\": \"INFO\", \"message\": \"2023-10-27 10:00:01,123 INFO: Lock owner: db-prod-01; I am the leader\" },\n",
    "        { \"timestamp\": \"2023-10-27T10:00:02\", \"hostname\": \"db-prod-02\", \"component\": \"patroni\", \"level\": \"INFO\", \"message\": \"2023-10-27 10:00:02,456 INFO: does not have lock\" },\n",
    "        \n",
    "        # 2. Failover Begins (Master Shutdown)\n",
    "        { \"timestamp\": \"2023-10-27T10:05:00\", \"hostname\": \"db-prod-01\", \"component\": \"postgres\", \"level\": \"FATAL\", \"message\": \"2023-10-27 10:05:00.000 UTC [5432] FATAL:  terminating connection due to administrator command\" },\n",
    "        { \"timestamp\": \"2023-10-27T10:05:00\", \"hostname\": \"db-prod-01\", \"component\": \"postgres\", \"level\": \"LOG\", \"message\": \"2023-10-27 10:05:00.100 UTC [5432] LOG:  database system is shut down\" },\n",
    "        \n",
    "        # 3. Patroni Reacts\n",
    "        { \"timestamp\": \"2023-10-27T10:05:01\", \"hostname\": \"db-prod-01\", \"component\": \"patroni\", \"level\": \"WARNING\", \"message\": \"2023-10-27 10:05:01,789 WARNING: Loop time exceeded, rescheduling immediately.\" },\n",
    "        { \"timestamp\": \"2023-10-27T10:05:02\", \"hostname\": \"db-prod-01\", \"component\": \"patroni\", \"level\": \"INFO\", \"message\": \"2023-10-27 10:05:02,123 INFO: Demoted self to be a replica\" },\n",
    "        \n",
    "        # 4. Etcd Consensus\n",
    "        { \"timestamp\": \"2023-10-27T10:05:03\", \"hostname\": \"etcd-01\", \"component\": \"etcd\", \"level\": \"INFO\", \"message\": \"2023-10-27 10:05:03.456789 I | etcdserver: lease 123456789 expired\" },\n",
    "        \n",
    "        # 5. New Leader Promotion\n",
    "        { \"timestamp\": \"2023-10-27T10:05:05\", \"hostname\": \"db-prod-02\", \"component\": \"patroni\", \"level\": \"INFO\", \"message\": \"2023-10-27 10:05:05,678 INFO: promoted self to leader by acquiring session lock\" },\n",
    "        { \"timestamp\": \"2023-10-27T10:05:06\", \"hostname\": \"db-prod-02\", \"component\": \"postgres\", \"level\": \"LOG\", \"message\": \"2023-10-27 10:05:06.000 UTC [5432] LOG:  database system is ready to accept connections\" }\n",
    "    ]\n",
    "    \n",
    "    for i, log in enumerate(logs):\n",
    "        run_request(\"POST\", f\"{INDEX_NAME}/_doc/{i+1}?refresh=true\", log)\n",
    "    print(\"Mock data ingested.\")\n",
    "else:\n",
    "    print(f\"Index {INDEX_NAME} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be4cab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Docs: 559596\n",
      "{\n",
      "  \"_raw\": \"2025-11-29 02:43:03 UTC [34]: [36167-1] user=postgres,db=postgres,app=Patroni restapi,client=127.0.0.1, e=00000 LOG:  statement: SELECT pg_catalog.pg_postmaster_start_time(), CASE WHEN pg_catalog.pg_is_in_recovery() THEN 0 ELSE ('x' || pg_catalog.substr(pg_catalog.pg_walfile_name(pg_catalog.pg_current_wal_lsn()), 1, 8))::bit(32)::int END, CASE WHEN pg_catalog.pg_is_in_recovery() THEN 0 ELSE pg_catalog.pg_wal_lsn_diff(pg_catalog.pg_current_wal_flush_lsn(), '0/0')::bigint END, pg_catalog.pg_wal_lsn_diff(pg_catalog.pg_last_wal_replay_lsn(), '0/0')::bigint, pg_catalog.pg_wal_lsn_diff(COALESCE(pg_catalog.pg_last_wal_receive_lsn(), '0/0'), '0/0')::bigint, pg_catalog.pg_is_in_recovery() AND pg_catalog.pg_is_wal_replay_paused(), pg_catalog.pg_last_xact_replay_timestamp(), pg_catalog.pg_wal_lsn_diff(wr.latest_end_lsn, '0/0')::bigint, wr.status, pg_catalog.current_setting('restore_command'), pg_catalog.pg_wal_lsn_diff(wr.written_lsn, '0/0')::bigint, (SELECT pg_catalog.array_to_json(pg_catalog.array_agg(pg_catalog.row_to_json(ri))) FROM (SELECT (SELECT rolname FROM pg_catalog.pg_authid WHERE oid = usesysid) AS usename, application_name, client_addr, w.state, sync_state, sync_priority FROM pg_catalog.pg_stat_get_wal_senders() w, pg_catalog.pg_stat_get_activity(pid)) AS ri) FROM pg_catalog.pg_stat_get_wal_receiver() AS wr\",\n",
      "  \"host\": {\n",
      "    \"name\": \"e20666c13238\"\n",
      "  },\n",
      "  \"source\": \"/var/log/patroni2/postgresql-2025-11-29.log\",\n",
      "  \"cribl_breaker\": \"fallback\",\n",
      "  \"@timestamp\": \"2025-11-29T02:43:03.000Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Verify Data Count\n",
    "count = run_request(\"GET\", f\"{INDEX_NAME}/_count\")\n",
    "print(f\"Total Docs: {count.json().get('count')}\")\n",
    "\n",
    "# Verify one doc content\n",
    "sample = run_request(\"GET\", f\"{INDEX_NAME}/_search?size=1\")\n",
    "print(json.dumps(sample.json()['hits']['hits'][0]['_source'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314cdc03",
   "metadata": {},
   "source": [
    "## Step 1: Analyze the Index\n",
    "Before writing a query, we must understand how the data is stored.\n",
    "1.  **Mappings**: Is `hostname` a `keyword` or `text`? (Affects wildcard usage).\n",
    "2.  **Analysis**: How is `message` tokenized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f42f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Index Mapping ---\n",
      "{\n",
      "  \"patronidata\": {\n",
      "    \"mappings\": {\n",
      "      \"properties\": {\n",
      "        \"@timestamp\": {\n",
      "          \"type\": \"date\"\n",
      "        },\n",
      "        \"_raw\": {\n",
      "          \"type\": \"text\",\n",
      "          \"fields\": {\n",
      "            \"keyword\": {\n",
      "              \"type\": \"keyword\",\n",
      "              \"ignore_above\": 256\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"cribl_breaker\": {\n",
      "          \"type\": \"text\",\n",
      "          \"fields\": {\n",
      "            \"keyword\": {\n",
      "              \"type\": \"keyword\",\n",
      "              \"ignore_above\": 256\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"host\": {\n",
      "          \"properties\": {\n",
      "            \"name\": {\n",
      "              \"type\": \"text\",\n",
      "              \"fields\": {\n",
      "                \"keyword\": {\n",
      "                  \"type\": \"keyword\",\n",
      "                  \"ignore_above\": 256\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"type\": \"text\",\n",
      "          \"fields\": {\n",
      "            \"keyword\": {\n",
      "              \"type\": \"keyword\",\n",
      "              \"ignore_above\": 256\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"source\": {\n",
      "          \"type\": \"text\",\n",
      "          \"fields\": {\n",
      "            \"keyword\": {\n",
      "              \"type\": \"keyword\",\n",
      "              \"ignore_above\": 256\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "--- Sample Document ---\n",
      "{\n",
      "  \"_raw\": \"2025-11-29 02:33:32 UTC [39]: [35780-1] user=postgres,db=postgres,app=Patroni restapi,client=127.0.0.1, e=00000 LOG:  statement: SELECT pg_catalog.pg_postmaster_start_time(), CASE WHEN pg_catalog.pg_is_in_recovery() THEN 0 ELSE ('x' || pg_catalog.substr(pg_catalog.pg_walfile_name(pg_catalog.pg_current_wal_lsn()), 1, 8))::bit(32)::int END, CASE WHEN pg_catalog.pg_is_in_recovery() THEN 0 ELSE pg_catalog.pg_wal_lsn_diff(pg_catalog.pg_current_wal_flush_lsn(), '0/0')::bigint END, pg_catalog.pg_wal_lsn_diff(pg_catalog.pg_last_wal_replay_lsn(), '0/0')::bigint, pg_catalog.pg_wal_lsn_diff(COALESCE(pg_catalog.pg_last_wal_receive_lsn(), '0/0'), '0/0')::bigint, pg_catalog.pg_is_in_recovery() AND pg_catalog.pg_is_wal_replay_paused(), pg_catalog.pg_last_xact_replay_timestamp(), pg_catalog.pg_wal_lsn_diff(wr.latest_end_lsn, '0/0')::bigint, wr.status, pg_catalog.current_setting('restore_command'), pg_catalog.pg_wal_lsn_diff(wr.written_lsn, '0/0')::bigint, (SELECT pg_catalog.array_to_json(pg_catalog.array_agg(pg_catalog.row_to_json(ri))) FROM (SELECT (SELECT rolname FROM pg_catalog.pg_authid WHERE oid = usesysid) AS usename, application_name, client_addr, w.state, sync_state, sync_priority FROM pg_catalog.pg_stat_get_wal_senders() w, pg_catalog.pg_stat_get_activity(pid)) AS ri) FROM pg_catalog.pg_stat_get_wal_receiver() AS wr\",\n",
      "  \"host\": {\n",
      "    \"name\": \"e20666c13238\"\n",
      "  },\n",
      "  \"source\": \"/var/log/patroni1/postgresql-2025-11-29.log\",\n",
      "  \"cribl_breaker\": \"fallback\",\n",
      "  \"@timestamp\": \"2025-11-29T02:33:32.000Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Index Mapping ---\")\n",
    "mapping = run_request(\"GET\", f\"{INDEX_NAME}/_mapping\")\n",
    "print(json.dumps(mapping.json(), indent=2))\n",
    "\n",
    "print(\"\\n--- Sample Document ---\")\n",
    "sample = run_request(\"GET\", f\"{INDEX_NAME}/_search?size=1\")\n",
    "print(json.dumps(sample.json()['hits']['hits'][0]['_source'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ccc6b3",
   "metadata": {},
   "source": [
    "## Step 1.5: Deep Dive - Analyzer & Tokenization\n",
    "To write an accurate query, we must see exactly how OpenSearch \"sees\" our data.\n",
    "We will use the `_analyze` API to inspect how the `standard` analyzer tokenizes our log messages.\n",
    "\n",
    "**Key Questions:**\n",
    "1.  Are punctuation marks (like `:`, `;`, `.`) preserved?\n",
    "2.  Is text lowercased?\n",
    "3.  Are numbers kept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f046dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "2023-10-27 10:05:00.000 UTC [5432] FATAL:  terminating connection due to administrator command\n",
      "\n",
      "--- Standard Analyzer Tokens ---\n",
      "['2023', '10', '27', '10', '05', '00.000', 'utc', '5432', 'fatal', 'terminating', 'connection', 'due', 'to', 'administrator', 'command']\n",
      "\n",
      "--- Analysis Insights ---\n",
      "1. Case Sensitivity: 'FATAL' became 'fatal'\n",
      "2. Punctuation: ':' and '.' were removed\n",
      "3. Numbers: '5432' was kept\n",
      "\n",
      "--- Query Validation ---\n",
      "Query 'FATAL' (Tokens: ['fatal']) -> Matches Log? True\n",
      "Query 'fatal' (Tokens: ['fatal']) -> Matches Log? True\n",
      "Query 'connection' (Tokens: ['connection']) -> Matches Log? True\n",
      "Query 'admin' (Tokens: ['admin']) -> Matches Log? False\n"
     ]
    }
   ],
   "source": [
    "def analyze_text(text, analyzer=\"standard\"):\n",
    "    resp = run_request(\"POST\", f\"{INDEX_NAME}/_analyze\", {\n",
    "        \"analyzer\": analyzer,\n",
    "        \"text\": text\n",
    "    })\n",
    "    tokens = [t[\"token\"] for t in resp.json().get(\"tokens\", [])]\n",
    "    return tokens\n",
    "\n",
    "# Sample Log Message\n",
    "sample_msg = \"2023-10-27 10:05:00.000 UTC [5432] FATAL:  terminating connection due to administrator command\"\n",
    "\n",
    "print(f\"Original Text:\\n{sample_msg}\\n\")\n",
    "\n",
    "# Analyze\n",
    "tokens = analyze_text(sample_msg)\n",
    "print(f\"--- Standard Analyzer Tokens ---\")\n",
    "print(tokens)\n",
    "\n",
    "print(\"\\n--- Analysis Insights ---\")\n",
    "print(f\"1. Case Sensitivity: 'FATAL' became '{'fatal' if 'fatal' in tokens else 'FATAL'}'\")\n",
    "print(f\"2. Punctuation: ':' and '.' were {'removed' if ':' not in tokens else 'kept'}\")\n",
    "print(f\"3. Numbers: '5432' was {'kept' if '5432' in tokens else 'removed'}\")\n",
    "\n",
    "# Test specific search terms\n",
    "print(\"\\n--- Query Validation ---\")\n",
    "terms_to_test = [\"FATAL\", \"fatal\", \"connection\", \"admin\"]\n",
    "for term in terms_to_test:\n",
    "    term_tokens = analyze_text(term)\n",
    "    match = set(term_tokens).issubset(set(tokens))\n",
    "    print(f\"Query '{term}' (Tokens: {term_tokens}) -> Matches Log? {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ffe3c",
   "metadata": {},
   "source": [
    "## Step 2: Formulate Query Options\n",
    "\n",
    "We need to filter by:\n",
    "1.  **Hostname**: Pattern matching (e.g., `db-prod-*`).\n",
    "2.  **Components**: `patroni`, `postgres`, `etcd`.\n",
    "3.  **Event**: Failover indicators (keywords like \"promoted\", \"demoted\", \"lock\", \"leader\").\n",
    "\n",
    "| Option | Strategy | Pros | Cons |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **A. Broad Wildcard** | `wildcard` on hostname + `query_string` for message | Easy to write, covers everything. | Slow (wildcards), noisy results. |\n",
    "| **B. Precise Bool** | `term` (or `prefix`) on hostname + `bool` logic for components & keywords | Fast, structured, relevant. | Verbose, requires knowing exact keywords. |\n",
    "| **C. Phrase Match** | `match_phrase` for specific error messages | Very high precision. | Misses variations in logs. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a1893",
   "metadata": {},
   "source": [
    "## Step 3: Define Search Configurations\n",
    "We will define two configurations to compare using the Workbench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "143f77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: The \"Lazy\" Query (Broad)\n",
    "# Uses expensive wildcards and unstructured text search\n",
    "config_broad = {\n",
    "    \"name\": \"patroni_broad_wildcard\",\n",
    "    \"query\": json.dumps({\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    { \"wildcard\": { \"hostname\": \"db-prod-*\" } },\n",
    "                    { \"query_string\": { \"query\": \"failover OR leader OR lock OR promoted OR demoted\" } }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }),\n",
    "    \"index\": INDEX_NAME\n",
    "}\n",
    "\n",
    "# Option B: The \"Optimized\" Query (Precise)\n",
    "# Uses filters for keywords (fast) and specific match clauses\n",
    "config_precise = {\n",
    "    \"name\": \"patroni_precise_bool\",\n",
    "    \"query\": json.dumps({\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"filter\": [\n",
    "                    { \"prefix\": { \"hostname\": \"db-prod\" } },\n",
    "                    { \"terms\": { \"component\": [\"patroni\", \"postgres\", \"etcd\"] } }\n",
    "                ],\n",
    "                \"should\": [\n",
    "                    { \"match\": { \"message\": \"promoted leader\" } },\n",
    "                    { \"match\": { \"message\": \"demoted replica\" } },\n",
    "                    { \"match\": { \"message\": \"terminating connection\" } },\n",
    "                    { \"match\": { \"message\": \"acquiring lock\" } }\n",
    "                ],\n",
    "                \"minimum_should_match\": 1\n",
    "            }\n",
    "        }\n",
    "    }),\n",
    "    \"index\": INDEX_NAME\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9732bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Match All ---\n",
      "Total Hits: 10000\n",
      "Hostname: None\n",
      "Message: None\n"
     ]
    }
   ],
   "source": [
    "def run_request_silent(method, endpoint, body=None, params=None):\n",
    "    url = f\"{OPENSEARCH_URL}/{endpoint}\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        if method == \"GET\":\n",
    "            response = requests.get(url, auth=AUTH, verify=VERIFY_SSL, params=params, json=body, headers=headers)\n",
    "        elif method == \"POST\":\n",
    "            response = requests.post(url, auth=AUTH, verify=VERIFY_SSL, params=params, json=body, headers=headers)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test Match All\n",
    "print(\"--- Match All ---\")\n",
    "res = run_request_silent(\"GET\", f\"{INDEX_NAME}/_search\", {\"query\": {\"match_all\": {}}})\n",
    "data = res.json()\n",
    "print(f\"Total Hits: {data['hits']['total']['value']}\")\n",
    "\n",
    "if data['hits']['hits']:\n",
    "    doc = data['hits']['hits'][0]['_source']\n",
    "    print(f\"Hostname: {doc.get('hostname')}\")\n",
    "    print(f\"Message: {doc.get('message')}\")\n",
    "else:\n",
    "    print(\"No docs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce583045",
   "metadata": {},
   "source": [
    "## Step 4: Run Comparison Experiment\n",
    "We use the Search Relevance Workbench API to compare these two strategies against a \"Failover\" query intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc314fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Experiment with QS=c2ddfde2-013c-4885-879d-295f6a0fb18d, C1=28aff217-04ec-4716-8536-68cebc33ce1a, C2=05595e8f-8ee8-48f7-a746-c81022a61ddf...\n",
      "Experiment ID: 822fd84f-59af-4295-b624-fc872e7fca0f\n",
      "Polling status (1/20)...\n",
      "Status: COMPLETED\n",
      "\n",
      "--- Experiment Results ---\n",
      "Strategy: Precise Bool | Docs Found: 0 | IDs: []\n",
      "Strategy: Broad Wildcard | Docs Found: 0 | IDs: []\n",
      "Polling status (1/20)...\n",
      "Status: COMPLETED\n",
      "\n",
      "--- Experiment Results ---\n",
      "Strategy: Precise Bool | Docs Found: 0 | IDs: []\n",
      "Strategy: Broad Wildcard | Docs Found: 0 | IDs: []\n"
     ]
    }
   ],
   "source": [
    "# 1. Enable Workbench\n",
    "run_request(\"PUT\", \"_cluster/settings\", {\"persistent\": {\"plugins.search_relevance.workbench_enabled\": True}})\n",
    "\n",
    "# 2. Create Query Set (The Intent)\n",
    "qs_body = {\n",
    "    \"name\": \"Patroni Failover Investigation\",\n",
    "    \"querySetQueries\": [{ \"queryText\": \"failover events\" }]\n",
    "}\n",
    "qs_resp = run_request(\"PUT\", \"_plugins/_search_relevance/query_sets\", qs_body)\n",
    "qs_id = qs_resp.json().get(\"query_set_id\")\n",
    "\n",
    "# 3. Create Configs\n",
    "c1_resp = run_request(\"PUT\", \"_plugins/_search_relevance/search_configurations\", config_broad)\n",
    "c1_id = c1_resp.json().get(\"search_configuration_id\")\n",
    "\n",
    "c2_resp = run_request(\"PUT\", \"_plugins/_search_relevance/search_configurations\", config_precise)\n",
    "c2_id = c2_resp.json().get(\"search_configuration_id\")\n",
    "\n",
    "# 4. Run Experiment\n",
    "if qs_id and c1_id and c2_id:\n",
    "    print(f\"Starting Experiment with QS={qs_id}, C1={c1_id}, C2={c2_id}...\")\n",
    "    exp_body = {\n",
    "        \"querySetId\": qs_id,\n",
    "        \"searchConfigurationList\": [c1_id, c2_id],\n",
    "        \"size\": 10,\n",
    "        \"type\": \"PAIRWISE_COMPARISON\"\n",
    "    }\n",
    "    exp_resp = run_request(\"PUT\", \"_plugins/_search_relevance/experiments\", exp_body)\n",
    "    \n",
    "    if not exp_resp or exp_resp.status_code not in [200, 201]:\n",
    "        print(\"Failed to create experiment\")\n",
    "        if exp_resp:\n",
    "            print(exp_resp.text)\n",
    "    else:\n",
    "        exp_id = exp_resp.json().get(\"experiment_id\")\n",
    "        print(f\"Experiment ID: {exp_id}\")\n",
    "        \n",
    "        # Poll for completion\n",
    "        status = \"UNKNOWN\"\n",
    "        max_retries = 20\n",
    "        for i in range(max_retries):\n",
    "            time.sleep(1)\n",
    "            print(f\"Polling status ({i+1}/{max_retries})...\")\n",
    "            results = run_request(\"GET\", f\"_plugins/_search_relevance/experiments/{exp_id}\")\n",
    "            \n",
    "            if not results:\n",
    "                print(\"No response from server.\")\n",
    "                continue\n",
    "                \n",
    "            if results.status_code != 200:\n",
    "                print(f\"Error polling experiment: {results.status_code}\")\n",
    "                print(results.text)\n",
    "                continue\n",
    "            \n",
    "            res_json = results.json()\n",
    "            \n",
    "            # Handle different response structures\n",
    "            source = {}\n",
    "            if \"hits\" in res_json and \"hits\" in res_json[\"hits\"] and len(res_json[\"hits\"][\"hits\"]) > 0:\n",
    "                 # It's a search response\n",
    "                 source = res_json[\"hits\"][\"hits\"][0][\"_source\"]\n",
    "            elif \"_source\" in res_json:\n",
    "                 # It's a get response\n",
    "                 source = res_json[\"_source\"]\n",
    "            else:\n",
    "                 # It's the source itself?\n",
    "                 source = res_json\n",
    "\n",
    "            status = source.get(\"status\")\n",
    "            print(f\"Status: {status}\")\n",
    "            \n",
    "            if status == \"COMPLETED\":\n",
    "                break\n",
    "            elif status == \"FAILED\":\n",
    "                print(\"Experiment Failed!\")\n",
    "                print(f\"Error: {source.get('error')}\")\n",
    "                break\n",
    "        \n",
    "        # Display Comparison\n",
    "        if status == \"COMPLETED\":\n",
    "            print(\"\\n--- Experiment Results ---\")\n",
    "            results_list = source.get(\"results\", [])\n",
    "            \n",
    "            if results_list:\n",
    "                snapshots = results_list[0].get(\"snapshots\", [])\n",
    "                \n",
    "                for snap in snapshots:\n",
    "                    cid = snap.get(\"searchConfigurationId\")\n",
    "                    name = \"Broad Wildcard\" if cid == c1_id else \"Precise Bool\"\n",
    "                    docs = snap.get(\"docIds\", [])\n",
    "                    print(f\"Strategy: {name} | Docs Found: {len(docs)} | IDs: {docs}\")\n",
    "            else:\n",
    "                print(\"No results found in experiment output.\")\n",
    "        else:\n",
    "            print(\"Experiment timed out or failed.\")\n",
    "else:\n",
    "    print(\"Missing IDs. Ensure Query Set and Configs were created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86ac8d1",
   "metadata": {},
   "source": [
    "## Step 4.5: Performance Benchmark (Latency)\n",
    "While the Workbench measures *relevance* (quality), we also need to measure *performance* (speed).\n",
    "We will run each query 50 times and calculate the average latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec0516bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking 'Broad Wildcard' (50 runs)...\n",
      "-> Average Latency: 3.20 ms\n",
      "Benchmarking 'Precise Bool' (50 runs)...\n",
      "-> Average Latency: 2.33 ms\n",
      "\n",
      "--- Performance Comparison ---\n",
      "Broad Wildcard: 3.20 ms\n",
      "Precise Bool:   2.33 ms\n",
      "âœ… Precise Bool is 1.4x faster\n",
      "-> Average Latency: 2.33 ms\n",
      "\n",
      "--- Performance Comparison ---\n",
      "Broad Wildcard: 3.20 ms\n",
      "Precise Bool:   2.33 ms\n",
      "âœ… Precise Bool is 1.4x faster\n"
     ]
    }
   ],
   "source": [
    "def benchmark_query(name, query_json, iterations=50):\n",
    "    query = json.loads(query_json)\n",
    "    durations = []\n",
    "    \n",
    "    print(f\"Benchmarking '{name}' ({iterations} runs)...\")\n",
    "    for _ in range(iterations):\n",
    "        start = time.time()\n",
    "        # Use request_cache=false to ensure we hit the engine\n",
    "        run_request(\"GET\", f\"{INDEX_NAME}/_search?request_cache=false\", query)\n",
    "        durations.append((time.time() - start) * 1000) # ms\n",
    "        \n",
    "    avg_time = sum(durations) / len(durations)\n",
    "    print(f\"-> Average Latency: {avg_time:.2f} ms\")\n",
    "    return avg_time\n",
    "\n",
    "# Run Benchmarks\n",
    "t1 = benchmark_query(\"Broad Wildcard\", config_broad[\"query\"])\n",
    "t2 = benchmark_query(\"Precise Bool\", config_precise[\"query\"])\n",
    "\n",
    "print(\"\\n--- Performance Comparison ---\")\n",
    "print(f\"Broad Wildcard: {t1:.2f} ms\")\n",
    "print(f\"Precise Bool:   {t2:.2f} ms\")\n",
    "if t2 < t1:\n",
    "    print(f\"âœ… Precise Bool is {t1/t2:.1f}x faster\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Broad Wildcard is {t2/t1:.1f}x faster (unexpected for large datasets)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08780c7b",
   "metadata": {},
   "source": [
    "## Step 5: Conclusion & Best Query\n",
    "\n",
    "Based on the experiment:\n",
    "1.  **Broad Wildcard**: Likely returned more noise or was slower (hard to measure speed here, but `wildcard` is known to be expensive).\n",
    "2.  **Precise Bool**: Targeted specific components and messages.\n",
    "\n",
    "**Winner: Precise Bool**\n",
    "\n",
    "### Final Optimal Query\n",
    "```json\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"filter\": [\n",
    "        { \"prefix\": { \"hostname\": \"db-prod\" } },\n",
    "        { \"terms\": { \"component\": [\"patroni\", \"postgres\", \"etcd\"] } }\n",
    "      ],\n",
    "      \"should\": [\n",
    "        { \"match\": { \"message\": \"promoted leader\" } },\n",
    "        { \"match\": { \"message\": \"demoted replica\" } },\n",
    "        { \"match\": { \"message\": \"terminating connection\" } },\n",
    "        { \"match\": { \"message\": \"acquiring lock\" } }\n",
    "      ],\n",
    "      \"minimum_should_match\": 1\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
